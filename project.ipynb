{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!jupyter kernelspec list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# import imageio as iio\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import color\n",
    "from skimage import io\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ROOT_FILE_PATH = \"/Users/adminpc-macmini/Library/CloudStorage/GoogleDrive-jeremias.rueck@gmail.com/Meine Ablage/Google Drive - Code/NTHU/final_project/data\"\n",
    "AREAS = [\"prf-visualrois\", \"floc-bodies\", \"floc-faces\", \"floc-places\", \"floc-words\", \"streams\", \"all-vertices\"]\n",
    "SUBJ_LIST = [\"subj01\", \"subj02\", \"subj03\", \"subj04\", \"subj05\", \"subj06\", \"subj07\", \"subj08\"]\n",
    "MASK_KEYS = [\"lh.fsaverage_space\", \"rh.fsaverage_space\", \"lh.space\", \"rh.space\", \"mapping\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadNpyFile(dir_path):\n",
    "  return_dic = {}\n",
    "  for path in glob.glob(dir_path + \"/*.npy\"):\n",
    "    filename = os.path.splitext(path)[0].split(\"/\")[-1]\n",
    "    return_dic[filename] = np.load(path, allow_pickle = True)\n",
    "  return return_dic\n",
    "\n",
    "def ReadFmriFile(dir_path):\n",
    "  return_dic = {}\n",
    "  for path in glob.glob(dir_path + \"/*.npy\"):\n",
    "    filename = os.path.splitext(path)[0].split(\"/\")[-1]\n",
    "    return_dic[filename[0]] = np.load(path, allow_pickle = True)\n",
    "  return return_dic\n",
    "\n",
    "def ReadMaskFile(dir_path):\n",
    "  return_dic = {area: {} for area in AREAS}\n",
    "  for path in glob.glob(dir_path + \"/*.npy\"):\n",
    "    filename = os.path.splitext(path)[0].split(\"/\")[-1]\n",
    "    for area in AREAS:\n",
    "      if area in filename:\n",
    "        filename = \"\".join(i.strip(\"_\") for i in filename.split(area))\n",
    "        return_dic[area][filename] = np.load(path, allow_pickle = True) if filename[0] != \"m\" else np.load(path, allow_pickle = True).item()\n",
    "        break\n",
    "  return return_dic\n",
    "\n",
    "def FetchPngFile(dir_path, index, mode = \"rgb\"):\n",
    "  # img = iio.v3.imread()\n",
    "  img = io.imread(os.path.join(dir_path, f'{index}.png'))\n",
    "  if mode == \"rgb\":\n",
    "    return img\n",
    "  if mode == \"hsv\":\n",
    "    return color.rgb2hsv(img)\n",
    "    # return matplotlib.colors.rgb_to_hsv(img)\n",
    "  if mode == \"gray\":\n",
    "    return color.rgb2gray(img)\n",
    "    # return np.dot(img, [0.299, 0.587, 0.114])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_val_split(x, y, ratio, random_state=42):\n",
    "  \n",
    "  r = np.random.RandomState(random_state)\n",
    "  \n",
    "  idx = r.permutation(x.index)\n",
    "  x_per = x.reindex(idx)\n",
    "  y_per = y.reindex(idx)\n",
    "\n",
    "  train_size = int(x.shape[0] * ratio)\n",
    "  \n",
    "  x_train = x_per[0:train_size]\n",
    "  y_train = y_per[0:train_size]\n",
    "  \n",
    "  x_val = x_per[train_size:]\n",
    "  y_val = y_per[train_size:]\n",
    "  \n",
    "  print('Training_dimension: ' + str(x_train.shape) + ' | ' + str(y_train.shape))\n",
    "  print('Validation_dimension: ' + str(x_val.shape) + ' | ' + str(y_val.shape))\n",
    "\n",
    "  return x_train, x_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadObject:\n",
    "  \n",
    "  fmri = None           # dict(string -> ndarray, float32)\n",
    "  masks = None          # dict(string \"AREA\" -> (dict(int -> string), string \"HEMISPHERE, \" -> ndarray))\n",
    "  \n",
    "  image_labels = None   # dataframe\n",
    "  label_names = None    # list\n",
    "\n",
    "  subject = None        # string\n",
    "  \n",
    "  def __init__(self, subject):\n",
    "    self.subject = subject\n",
    "\n",
    "  # Mode = \"train\" | \"test\"\n",
    "  def load(self, mode = \"train\"):\n",
    "    \n",
    "    self.image_labels = pd.read_csv(os.path.join(ROOT_FILE_PATH, \"image_infos\", f\"{self.subject}_infos_train.csv\"))\n",
    "    self.image_labels = self.image_labels.drop(self.image_labels.columns[[0, 1]], axis=1)\n",
    "    self.label_names = self.image_labels.columns\n",
    "    \n",
    "    self.image_labels = self.image_labels.to_numpy(dtype=int)\n",
    "\n",
    "    print('Images: ' + str(self.image_labels.shape[0]))\n",
    "    print('Labels: ' + str(self.image_labels.shape[1]))\n",
    "    \n",
    "    self.masks = ReadMaskFile(os.path.join(ROOT_FILE_PATH, self.subject , \"roi_masks\"))\n",
    "    print('Masks: ' + str(len(self.masks.keys())))\n",
    "        \n",
    "    if mode == \"train\":\n",
    "      self.fmri = ReadFmriFile(os.path.join(ROOT_FILE_PATH, self.subject, \"training_split\", \"training_fmri\"))\n",
    "    elif mode == \"test\":\n",
    "      self.fmri = ReadFmriFile(os.path.join(ROOT_FILE_PATH, self.subject, \"test_split\", \"test_fmri\"))\n",
    "\n",
    "  def split_data(self, count=None, ratio=None, permutate=True, image_mode = \"rgb\", random_state=42):\n",
    "    \n",
    "    if ratio is None:\n",
    "      ratio = 1\n",
    "    \n",
    "    random_state = np.random.RandomState(random_state)\n",
    "    \n",
    "    if count is not None and count > 0:\n",
    "      fmri_l_copy = self.fmri['l'][:count]\n",
    "      fmri_r_copy = self.fmri['r'][:count]\n",
    "      labels_copy = self.image_labels[:count]\n",
    "    else:\n",
    "      fmri_l_copy = self.fmri['l']\n",
    "      fmri_r_copy = self.fmri['r']\n",
    "      labels_copy = self.image_labels\n",
    "    \n",
    "    loaded_images = np.stack([FetchPngFile(os.path.join(ROOT_FILE_PATH, self.subject,\n",
    "                      \"training_split\", \"training_images\"), i, mode = image_mode) for i in range(labels_copy.shape[0])])\n",
    "    \n",
    "    if permutate:\n",
    "      \n",
    "        idx = random_state.permutation(labels_copy.shape[0])\n",
    "        \n",
    "        fmri_l_copy = fmri_l_copy[idx]\n",
    "        fmri_r_copy = fmri_r_copy[idx]\n",
    "        labels_copy = labels_copy[idx]\n",
    "        loaded_images = loaded_images[idx]\n",
    "        \n",
    "    train_size = int(labels_copy.shape[0] * ratio)\n",
    "  \n",
    "    fmri_l_train = fmri_l_copy[0:train_size]\n",
    "    fmri_r_train = fmri_r_copy[0:train_size]\n",
    "    labels_train = labels_copy[0:train_size]\n",
    "    images_train = loaded_images[0:train_size]\n",
    "    \n",
    "    fmri_l_val = fmri_l_copy[train_size:]\n",
    "    fmri_r_val = fmri_r_copy[train_size:]\n",
    "    labels_val = labels_copy[train_size:]\n",
    "    images_val = loaded_images[train_size:]\n",
    "    \n",
    "    return (labels_train, labels_val), (fmri_l_train, fmri_l_val), (fmri_r_train, fmri_r_val), (images_train, images_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def test_data(label_names, labels_list, image, fmri_l, fmri_r):\n",
    "  labels = np.array(label_names)[np.where(labels_list != 0)] \n",
    "  print(labels)\n",
    "  plt.imshow(image)\n",
    "  plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = ReadObject(SUBJ_LIST[0])\n",
    "obj.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(\n",
    "  (labels_train, labels_val), (fmri_l_train, fmri_l_val),\n",
    "  (fmri_r_train, fmri_r_val), (images_train, images_val)\n",
    ") = (obj.split_data(count=5000, ratio=0.995, image_mode= \"rgb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(labels_train.shape)\n",
    "print(labels_val.shape)\n",
    "print(fmri_l_train.shape)\n",
    "print(fmri_l_val.shape)\n",
    "print(fmri_r_train.shape)\n",
    "print(fmri_r_val.shape)\n",
    "print(images_train.shape)\n",
    "print(images_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "index = 183\n",
    "test_data(obj.label_names, labels_train[index], images_train[index], None, None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(images_train.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(fmri_l_train.shape)\n",
    "print(fmri_r_train.shape)\n",
    "X_train = combined_array = np.concatenate((fmri_l_train, fmri_r_train), axis=1)\n",
    "print(X_train.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.max(X_train))\n",
    "print(np.min(X_train))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the original range\n",
    "old_min = np.min(X_train)\n",
    "old_max = np.max(X_train)\n",
    "\n",
    "# Define the new range you want to map to\n",
    "new_min = 0\n",
    "new_max = 1\n",
    "\n",
    "# Map the values from the original range to the new range\n",
    "mapped_X_train = (X_train - old_min) * (new_max - new_min) / (old_max - old_min) + new_min\n",
    "\n",
    "print(np.min(mapped_X_train))\n",
    "print(np.max(mapped_X_train))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_train = labels_train\n",
    "print(Y_train.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "# Image classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv1D(filters=32, kernel_size=(8,), activation=keras.layers.LeakyReLU(), input_shape=(39548, 1)))\n",
    "model.add(keras.layers.Conv1D(filters=32, kernel_size=(8,), activation=keras.layers.LeakyReLU()))\n",
    "model.add(keras.layers.MaxPool1D())\n",
    "\n",
    "model.add(keras.layers.Conv1D(filters=64, kernel_size=(4,), activation=keras.layers.LeakyReLU()))\n",
    "model.add(keras.layers.Conv1D(filters=64, kernel_size=(4,), activation=keras.layers.LeakyReLU()))\n",
    "model.add(keras.layers.MaxPool1D())\n",
    "\n",
    "model.add(keras.layers.Conv1D(filters=128, kernel_size=(3,), activation=keras.layers.LeakyReLU()))\n",
    "model.add(keras.layers.Conv1D(filters=128, kernel_size=(3,), activation=keras.layers.LeakyReLU()))\n",
    "model.add(keras.layers.MaxPool1D())\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "model.add(keras.layers.Dense(512, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(256, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(133, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]) # keras.optimizers.Adam(learning_rate=0.000001)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(X_train.reshape(-1, mapped_X_train.shape[1], 1), Y_train, batch_size=32, epochs=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "# Image reconstruction 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fill with zeros till 40000\n",
    "target_size = 40000\n",
    "additional_rows = np.zeros(shape=(4975, target_size - X_train.shape[1]))\n",
    "print(additional_rows.shape)\n",
    "expanded_40000_X_train = np.concatenate((X_train, additional_rows), axis=1)\n",
    "print(expanded_40000_X_train.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "count = 500\n",
    "resized_300_Y_train = np.zeros((count, 300, 300, 3))\n",
    "for index in range(count):\n",
    "  print(index)\n",
    "  resized_300_Y_train[index] = resize(images_train[index], (300, 300, 3), anti_aliasing=True)\n",
    "print(resized_300_Y_train.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder1 = keras.models.Sequential()\n",
    "\n",
    "encoder1.add(keras.layers.Conv2D(1, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", input_shape=(200, 200, 1)))\n",
    "\n",
    "encoder1.add(keras.layers.Conv2D(32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "encoder1.add(keras.layers.Conv2D(32, kernel_size=(3, 3), padding=\"same\", activation=\"sigmoid\"))\n",
    "encoder1.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "encoder1.add(keras.layers.Conv2D(64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "encoder1.add(keras.layers.Conv2D(64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "encoder1.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "encoder1.add(keras.layers.Conv2D(128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "encoder1.add(keras.layers.Conv2D(128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "encoder1.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "encoder1.summary()\n",
    "\n",
    "decoder1 = keras.models.Sequential()\n",
    "\n",
    "decoder1.add(keras.layers.Conv2D(128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", input_shape=(25, 25, 128)))\n",
    "decoder1.add(keras.layers.Conv2D(128, kernel_size=(3, 3), padding=\"same\", activation=\"sigmoid\"))\n",
    "decoder1.add(keras.layers.UpSampling2D(size=(3, 3)))\n",
    "\n",
    "decoder1.add(keras.layers.Conv2D(64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "decoder1.add(keras.layers.Conv2D(64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "decoder1.add(keras.layers.UpSampling2D(size=(2, 2)))\n",
    "\n",
    "decoder1.add(keras.layers.Conv2D(32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "decoder1.add(keras.layers.Conv2D(32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "decoder1.add(keras.layers.UpSampling2D(size=(2, 2)))\n",
    "\n",
    "decoder1.add(keras.layers.Conv2D(3, kernel_size=(3, 3), padding=\"same\", activation=\"sigmoid\"))\n",
    "decoder1.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model1 = keras.models.Sequential()\n",
    "model1.add(encoder1)\n",
    "model1.add(decoder1)\n",
    "\n",
    "model1.compile(optimizer=\"sgd\", loss=\"mse\") # \"adam\", \"rmsprop\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model1.fit(expanded_40000_X_train.reshape(-1, 200, 200)[:500], resized_300_Y_train, batch_size=32, epochs=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "# Image reconstruction 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "count = 500\n",
    "resized_200_Y_train = np.zeros((count, 200, 200, 3))\n",
    "for index in range(count):\n",
    "  print(index)\n",
    "  resized_200_Y_train[index] = resize(images_train[index], (200, 200, 3), anti_aliasing=True)\n",
    "print(resized_200_Y_train.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder2 = keras.models.Sequential()\n",
    "\n",
    "encoder2.add(keras.layers.Conv2D(32, kernel_size=4, strides=2, input_shape=(200, 200, 1)))\n",
    "encoder2.add(keras.layers.BatchNormalization())\n",
    "encoder2.add(keras.layers.LeakyReLU())\n",
    "encoder2.add(keras.layers.Dropout(0.1))\n",
    "\n",
    "encoder2.add(keras.layers.Conv2D(64, kernel_size=3, strides=2))\n",
    "encoder2.add(keras.layers.BatchNormalization())\n",
    "encoder2.add(keras.layers.LeakyReLU())\n",
    "encoder2.add(keras.layers.Dropout(0.1))\n",
    "\n",
    "encoder2.summary()\n",
    "\n",
    "bridge2 = keras.models.Sequential()\n",
    "\n",
    "bridge2.add(keras.layers.Conv2D(128, kernel_size=3, strides=2, input_shape=(49, 49, 64)))\n",
    "\n",
    "bridge2.summary()\n",
    "\n",
    "decoder2 = keras.models.Sequential()\n",
    "\n",
    "decoder2.add(keras.layers.Dropout(0.1, input_shape=(24, 24, 128)))\n",
    "decoder2.add(keras.layers.LeakyReLU())\n",
    "decoder2.add(keras.layers.BatchNormalization())\n",
    "decoder2.add(keras.layers.Conv2DTranspose(64, kernel_size=3, strides=2))\n",
    "decoder2.add(keras.layers.BatchNormalization())\n",
    "decoder2.add(keras.layers.LeakyReLU())\n",
    "decoder2.add(keras.layers.Dropout(0.1))\n",
    "\n",
    "decoder2.add(keras.layers.Conv2DTranspose(32, kernel_size=3, strides=2))\n",
    "decoder2.add(keras.layers.BatchNormalization())\n",
    "decoder2.add(keras.layers.LeakyReLU())\n",
    "decoder2.add(keras.layers.Dropout(0.1))\n",
    "\n",
    "decoder2.add(keras.layers.Conv2DTranspose(3, kernel_size=4, strides=2))\n",
    "\n",
    "decoder2.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model2 = keras.models.Sequential()\n",
    "\n",
    "model2.add(encoder2)\n",
    "model2.add(bridge2)\n",
    "model2.add(decoder2)\n",
    "\n",
    "model2.summary()\n",
    "model2.compile(optimizer=\"sgd\", loss=\"mse\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model2.fit(expanded_40000_X_train.reshape(-1, 200, 200)[:500], resized_200_Y_train, batch_size=32, epochs=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scaling_vis_enc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
